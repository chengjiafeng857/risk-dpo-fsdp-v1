policy_model: meta-llama/Llama-3.1-8B-Instruct
ref_model: meta-llama/Llama-3.1-8B-Instruct
precision: bf16

dataset:
  dataset_name: Anthropic/hh-rlhf
  subset: train[:20%]
  val_ratio: 0.1
  seed: 42
  max_len: 512
  
dpo_training:
  epochs: 1
  batch_size: 16
  learning_rate: 5e-7
  log_steps: 10
  warmup_steps: 120
  max_grad_norm: 10
  dpo_beta: 0.1
  save_dir: dpo_model

tail_test:
  delta: 0.1
  lambda: 0.05
  log_dir: logs/margins